{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1519c9",
   "metadata": {},
   "source": [
    "\n",
    "# Individual Homework: Data Preparation and Exploratory Analysis\n",
    "\n",
    "**Due:** 21 Sep 2025, 11:59 pm (SGT)  \n",
    "**Submission:** Single `your_name_assignment1.ipynb` file uploaded to Canvas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d7511",
   "metadata": {},
   "source": [
    "## Student details\n",
    "Fill this in before you start.\n",
    "\n",
    "- Student ID:\n",
    "\n",
    "  - Example: e1234567\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa63a206",
   "metadata": {},
   "source": [
    "## 0. Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import packages you need. Keep to the standard stack where possible.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# If you need scikit-learn later, you can import it when required.\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "\n",
    "# Display options for readability\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "# Set a seed for any random processes used later\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "print('Set-up complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c4afb7",
   "metadata": {},
   "source": [
    "## 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset dummy_homework_dataset.csv has been provided for you.\n",
    "# It must be used for this homework assignment.\n",
    "\n",
    "csv_path = 'tcx3213_assignment1_dataset.csv'  # This is the provided dataset file\n",
    "\n",
    "# Load the dataset\n",
    "# HINT: Use the appropriate pandas function to read the CSV file into a dataframe\n",
    "# HINT: After loading, display the first few rows to check if the dataset loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4511c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick structure check\n",
    "# HINT: Write code to display a concise summary of the dataframe, including column names, data types, and non-null counts\n",
    "# HINT: Write code to display summary statistics for both numeric and non-numeric columns in a table format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a99775",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 Basic dataset notes\n",
    "Briefly describe:\n",
    "- What each column represents (in your own words)\n",
    "- The size of the dataset (rows and columns)\n",
    "- Any obvious data quality issues you notice at first glance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c93549",
   "metadata": {},
   "source": [
    "## 2. Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a56b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "# HINT: Write code to select columns with numeric data types and store them in a list\n",
    "# HINT: Write code to select columns with non-numeric (categorical) data types and store them in a list\n",
    "\n",
    "# Print your lists to confirm\n",
    "# HINT: Write code to print the names of numeric columns\n",
    "# HINT: Write code to print the names of categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb095b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for numeric columns\n",
    "# HINT: Loop through each numeric column in your list\n",
    "# HINT: For each column, create a new figure\n",
    "# HINT: Plot a histogram for the column with a suitable number of bins\n",
    "# HINT: Add a title showing the column name\n",
    "# HINT: Label the x-axis and y-axis clearly\n",
    "# HINT: Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35326184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic bivariate exploration (example: correlation heatmap for numeric columns)\n",
    "# HINT: Compute the correlation matrix for all numeric columns in the dataframe\n",
    "# HINT: Create a new figure for the heatmap\n",
    "# HINT: Use a plotting function to display the correlation matrix as a heatmap\n",
    "# HINT: Add a colour bar to show correlation strength\n",
    "# HINT: Set the title of the plot\n",
    "# HINT: Add x-axis and y-axis tick labels using column names, rotated for readability\n",
    "# HINT: Adjust the layout so labels and the heatmap fit nicely\n",
    "# HINT: Display the final heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531758f7",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Notes from EDA\n",
    "Summarise key observations:\n",
    "- Which variables are skewed or have outliers\n",
    "- Obvious relationships or lack of relationships\n",
    "- Potential target variable if you choose to build a tiny baseline model later (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48b62f",
   "metadata": {},
   "source": [
    "## 3. Missing data analysis and handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a3d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check overall missingness\n",
    "# HINT: Calculate the number of missing values in each column\n",
    "# HINT: Sort the missing value counts from highest to lowest\n",
    "# HINT: Compute the percentage of missing values for each column\n",
    "# HINT: Combine both counts and percentages into a single summary table for easy viewing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b64de",
   "metadata": {},
   "source": [
    "\n",
    "### Plan your approach\n",
    "For each feature with missing values, write your plan:\n",
    "- Impute with mean or median for numeric with mild skew\n",
    "- Impute with mode for categorical\n",
    "- Consider more suitable methods if needed\n",
    "Explain your choice briefly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example skeleton for applying simple imputations\n",
    "\n",
    "# HINT: Decide on a strategy for imputing missing numeric values (e.g., mean or median)\n",
    "# HINT: Decide on a strategy for imputing missing categorical values (e.g., most frequent)\n",
    "\n",
    "# HINT: Loop through each numeric column\n",
    "# HINT: If the column has missing values, replace them using the chosen numeric strategy\n",
    "\n",
    "# HINT: Loop through each categorical column\n",
    "# HINT: If the column has missing values, replace them using the chosen categorical strategy\n",
    "\n",
    "# HINT: You can use pandas fillna() or sklearn SimpleImputer for this step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0816cab",
   "metadata": {},
   "source": [
    "## 4. Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify ordinal columns that have a natural order\n",
    "# HINT: Look at your categorical columns and decide which ones have an inherent order (e.g., low < medium < high)\n",
    "# HINT: Create a mapping dictionary to assign numeric values based on the order you identified\n",
    "# HINT: Apply the mapping to transform the ordinal column into numeric form\n",
    "\n",
    "# One-hot encoding for nominal columns\n",
    "# HINT: For categorical columns without natural order, use one-hot encoding to create dummy variables\n",
    "# HINT: Decide whether to drop the first category to avoid multicollinearity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4fc08",
   "metadata": {},
   "source": [
    "\n",
    "Explain your encoding choices:\n",
    "- Which columns were treated as ordinal and why\n",
    "- Which columns were one-hot encoded and why\n",
    "- Any categories you combined or cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c4d1d6",
   "metadata": {},
   "source": [
    "## 5. Scaling, normalisation, and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e577318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect skewness\n",
    "# HINT: Calculate the skewness for each numeric column in the dataframe\n",
    "# HINT: Sort the skewness values in descending order to see which columns are most skewed\n",
    "# HINT: Decide which columns might need transformations based on their skewness values\n",
    "\n",
    "# Apply transformations where helpful (example: log1p for positive skew)\n",
    "# HINT: Loop through each numeric column\n",
    "# HINT: For columns with strong positive skew, apply a suitable transformation (e.g., log1p) to reduce skewness\n",
    "# HINT: Create new transformed columns rather than overwriting original columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling example placeholders\n",
    "# HINT: Decide whether to use standardisation (StandardScaler) or normalisation (MinMaxScaler) based on your analysis needs\n",
    "# HINT: Create a copy of your dataframe before applying scaling\n",
    "# HINT: Apply the scaler to the numeric columns only\n",
    "# HINT: Check the first few rows of the scaled dataframe to confirm changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd490dd",
   "metadata": {},
   "source": [
    "\n",
    "Briefly justify your choices:\n",
    "- Which columns you transformed and why\n",
    "- Which scaling method you used and why\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84ae5d",
   "metadata": {},
   "source": [
    "## 6. Feature selection (basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter-based selection examples\n",
    "\n",
    "# Option A: remove highly correlated features\n",
    "# HINT: Calculate the absolute correlation matrix for numeric columns\n",
    "# HINT: Extract the upper triangle of the correlation matrix to avoid duplicates\n",
    "# HINT: Identify columns with correlation above a chosen threshold (e.g., 0.9)\n",
    "# HINT: Drop the highly correlated columns from the dataframe\n",
    "\n",
    "# Option B: mutual information (choose appropriate function for your target type)\n",
    "# HINT: Choose the correct mutual information function based on the target type\n",
    "#       - mutual_info_regression for continuous targets\n",
    "#       - mutual_info_classif for categorical targets\n",
    "# HINT: Apply mutual information to all features except the target column\n",
    "# HINT: Rank features by their MI scores and decide which ones to keep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d26b7",
   "metadata": {},
   "source": [
    "\n",
    "Write a short note describing the selected features and why they are suitable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb0066",
   "metadata": {},
   "source": [
    "## 7. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f376e8d",
   "metadata": {},
   "source": [
    "Summarise what you did and learned. State any assumptions or limitations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa93fbb",
   "metadata": {},
   "source": [
    "Write your conclusions here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc861fb",
   "metadata": {},
   "source": [
    "## Marking rubrics\n",
    "\n",
    "### Summary rubric (100 marks)\n",
    "\n",
    "| Section                        | Criteria                                                                                          | Marks |\n",
    "|--------------------------------|---------------------------------------------------------------------------------------------------|-------|\n",
    "| 0. Set-up                       | Clean imports, seed set, readable options                                                        | 5     |\n",
    "| 1. Load and describe             | Correct load, preview, clear description of columns, correct data types description              | 10    |\n",
    "| 2. EDA                           | Correct identification of numeric and categorical, sensible plots, correct observations about skewness and relationships | 20    |\n",
    "| 3. Missing data                  | Accurate audit, reasonable plan, correct implementation, justification                           | 20    |\n",
    "| 4. Encoding                      | Correct identification of ordinal vs nominal, appropriate encodings, explanation                 | 15    |\n",
    "| 5. Scaling and transformation    | Correct skew checks, reasonable use of transformations, correct scaling choice with justification | 15    |\n",
    "| 6. Feature selection             | Correct method, coherent threshold or MI use, clear explanation                                  | 10    |\n",
    "| 7. Conclusions                   | Clear summary and limitations                                                                    | 5     |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Detailed rubrics\n",
    "\n",
    "| Section                     | Excellent                                                                                                         | Satisfactory                                    | Needs work                             | Common pitfalls                                                        |\n",
    "|-----------------------------|-------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------|------------------------------------------------------------------------|\n",
    "| 1. Load and describe         | Loads correctly, concise but informative column descriptions, correct dtype commentary                           | Loads correctly with brief notes                | Loads with errors or missing notes      | Forgetting to set the correct file name, no info() or describe()         |\n",
    "| 2. EDA                       | All relevant plots, clear notes on skew and outliers, simple correlation heatmap                                  | Some plots, some comments                        | Minimal plots, little commentary        | Plotting unreadable figures, no labels or titles                         |\n",
    "| 3. Missing data              | Complete audit table, choices justified by type and distribution, implementation correct                         | Partial audit, basic fill rules used             | Incomplete audit, unjustified methods   | Imputing strings with numeric strategies, leaving NaN without explanation|\n",
    "| 4. Encoding                  | Correct ordinal maps, appropriate one-hot, clear rationale                                                        | Mostly correct encodings                         | Incorrect or unexplained encodings       | Treating nominal as ordinal, exploding cardinality without discussion    |\n",
    "| 5. Scaling and transformation| Sound skew checks, appropriate transforms, correct scaler choice and reasoning                                   | Some transforms or scaling with basic reasoning | Misapplied transforms or no reasoning    | Applying log to zeros or negatives, scaling before fixing missing values |\n",
    "| 6. Feature selection         | Method well explained, threshold or mutual information (MI) sensibly chosen, clean reduced set                                         | Some selection with light explanation            | No clear method or arbitrary drops        | Using target leakage, dropping at random                                 |\n",
    "| 7. Conclusions               | Clear synthesis, limitations acknowledged                                                                        | Basic summary                                   | Vague or missing                        | No link between steps and conclusions                                    |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
