{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f88883",
   "metadata": {},
   "source": [
    "# ðŸ“§ Email Classification - Feature Selection Practice\n",
    "\n",
    "**Learning Goal:** Practice feature selection techniques using a real-world email classification problem.\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57025b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE, VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdcfbbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ STEP 1: Create Email Dataset\n",
    "\n",
    "### Q1: What makes a good classification dataset?\n",
    "\n",
    "**Answer:** A dataset with a naturally categorical target variable that we want to predict.\n",
    "\n",
    "**Our Problem:** Classify emails as **SPAM**, **PROMOTIONAL**, or **PERSONAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2d3a70ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“§ Email Classification Dataset:\n",
      "   word_count  exclamation_marks  capital_letters  links_count  time_of_day  \\\n",
      "0          45                  0                5            0            9   \n",
      "1          15                  1                3            0           22   \n",
      "2          60                  1                8            1           20   \n",
      "3          35                  1                6            0           21   \n",
      "4          40                  0                7            1            7   \n",
      "5          55                  2                9            1           19   \n",
      "6          30                  0                4            0            8   \n",
      "7          65                  1               10            1           23   \n",
      "8          38                  1                6            0           18   \n",
      "9          42                  0                5            0            6   \n",
      "\n",
      "  sender_domain  has_attachment  weekend_sent email_type  \n",
      "0         gmail               0             1   Personal  \n",
      "1         gmail               0             1   Personal  \n",
      "2         gmail               0             1   Personal  \n",
      "3       hotmail               1             1   Personal  \n",
      "4         gmail               0             1   Personal  \n",
      "5         yahoo               1             0   Personal  \n",
      "6       hotmail               0             1   Personal  \n",
      "7         gmail               0             0   Personal  \n",
      "8         yahoo               1             0   Personal  \n",
      "9         gmail               0             1   Personal  \n",
      "\n",
      "Dataset shape: (30, 9)\n",
      "\n",
      "Target distribution:\n",
      "email_type\n",
      "Personal       10\n",
      "Promotional    10\n",
      "Spam           10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create an email dataset\n",
    "email_data = {\n",
    "    'word_count': [\n",
    "        # Personal emails (10 samples) - typically shorter, casual\n",
    "        45, 15, 60, 35, 40, 55, 30, 65, 38, 42,\n",
    "        # Promotional emails (10 samples) - medium length, business-like\n",
    "        120, 80, 150, 90, 170, 110, 95, 140, 85, 130,\n",
    "        # Spam emails (10 samples) - often longer, sales-heavy\n",
    "        200, 300, 250, 280, 220, 350, 180, 320, 270, 240\n",
    "    ],\n",
    "    'exclamation_marks': [\n",
    "        # Personal emails - few exclamation marks\n",
    "        0, 1, 1, 1, 0, 2, 0, 1, 1, 0,\n",
    "        # Promotional emails - moderate exclamation marks\n",
    "        3, 2, 4, 3, 5, 2, 3, 4, 2, 3,\n",
    "        # Spam emails - many exclamation marks\n",
    "        8, 12, 9, 11, 7, 15, 6, 13, 10, 8\n",
    "    ],\n",
    "    'capital_letters': [\n",
    "        # Personal emails - few capitals\n",
    "        5, 3, 8, 6, 7, 9, 4, 10, 6, 5,\n",
    "        # Promotional emails - moderate capitals\n",
    "        25, 12, 20, 15, 28, 18, 14, 22, 16, 24,\n",
    "        # Spam emails - many capitals (shouting)\n",
    "        45, 60, 50, 55, 40, 70, 35, 65, 58, 48\n",
    "    ],\n",
    "    'links_count': [\n",
    "        # Personal emails - very few links\n",
    "        0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
    "        # Promotional emails - some links\n",
    "        2, 1, 3, 2, 3, 2, 1, 3, 2, 2,\n",
    "        # Spam emails - many links\n",
    "        5, 8, 6, 7, 4, 9, 3, 8, 6, 5\n",
    "    ],\n",
    "    'time_of_day': [\n",
    "        # Personal emails - varied times, including evenings/weekends\n",
    "        9, 22, 20, 21, 7, 19, 8, 23, 18, 6,\n",
    "        # Promotional emails - business hours\n",
    "        14, 16, 15, 17, 14, 10, 13, 16, 11, 15,\n",
    "        # Spam emails - often odd hours\n",
    "        10, 11, 13, 12, 2, 3, 1, 4, 23, 0\n",
    "    ],\n",
    "    'sender_domain': [\n",
    "        # Personal emails - personal domains\n",
    "        'gmail', 'gmail', 'gmail', 'hotmail', 'gmail', 'yahoo', 'hotmail', 'gmail', 'yahoo', 'gmail',\n",
    "        # Promotional emails - company domains\n",
    "        'company', 'work', 'company', 'work', 'company', 'work', 'company', 'work', 'company', 'work',\n",
    "        # Spam emails - suspicious domains\n",
    "        'promo', 'ads', 'promo', 'ads', 'promo', 'ads', 'promo', 'ads', 'promo', 'ads'\n",
    "    ],\n",
    "    'has_attachment': [\n",
    "        # Personal emails - sometimes attachments\n",
    "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
    "        # Promotional emails - often have attachments (brochures, etc.)\n",
    "        1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
    "        # Spam emails - rarely legitimate attachments\n",
    "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1\n",
    "    ],\n",
    "    'weekend_sent': [\n",
    "        # Personal emails - often sent on weekends\n",
    "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
    "        # Promotional emails - usually business days\n",
    "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
    "        # Spam emails - sent any time\n",
    "        0, 1, 0, 0, 1, 0, 1, 0, 1, 0\n",
    "    ],\n",
    "    'email_type': [\n",
    "        # 10 Personal emails\n",
    "        'Personal', 'Personal', 'Personal', 'Personal', 'Personal', \n",
    "        'Personal', 'Personal', 'Personal', 'Personal', 'Personal',\n",
    "        # 10 Promotional emails\n",
    "        'Promotional', 'Promotional', 'Promotional', 'Promotional', 'Promotional',\n",
    "        'Promotional', 'Promotional', 'Promotional', 'Promotional', 'Promotional',\n",
    "        # 10 Spam emails\n",
    "        'Spam', 'Spam', 'Spam', 'Spam', 'Spam',\n",
    "        'Spam', 'Spam', 'Spam', 'Spam', 'Spam'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(email_data)\n",
    "\n",
    "print(\"ðŸ“§ Email Classification Dataset:\")\n",
    "print(df.head(10))\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['email_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e907a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ” STEP 2: Understand Your Features\n",
    "\n",
    "### Q2: What information helps identify spam emails?\n",
    "\n",
    "**Answer:** Look at patterns that distinguish between email types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0dc5e84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature descriptions:\n",
      "â€¢ word_count: Number of words in email\n",
      "â€¢ exclamation_marks: Number of ! marks\n",
      "â€¢ capital_letters: Number of CAPITAL letters\n",
      "â€¢ links_count: Number of hyperlinks\n",
      "â€¢ time_of_day: Hour email was sent (0-23)\n",
      "â€¢ sender_domain: Email domain type\n",
      "â€¢ has_attachment: Has file attachment (0/1)\n",
      "â€¢ weekend_sent: Sent on weekend (0/1)\n",
      "\n",
      "ðŸ“Š Feature patterns by email type:\n",
      "\n",
      "Personal emails:\n",
      "  Avg exclamation marks: 0.7\n",
      "  Avg capital letters: 6.3\n",
      "  Avg links: 0.4\n",
      "\n",
      "Promotional emails:\n",
      "  Avg exclamation marks: 3.1\n",
      "  Avg capital letters: 19.4\n",
      "  Avg links: 2.1\n",
      "\n",
      "Spam emails:\n",
      "  Avg exclamation marks: 9.9\n",
      "  Avg capital letters: 52.6\n",
      "  Avg links: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFeature descriptions:\")\n",
    "feature_descriptions = {\n",
    "    'word_count': 'Number of words in email',\n",
    "    'exclamation_marks': 'Number of ! marks',\n",
    "    'capital_letters': 'Number of CAPITAL letters',\n",
    "    'links_count': 'Number of hyperlinks',\n",
    "    'time_of_day': 'Hour email was sent (0-23)',\n",
    "    'sender_domain': 'Email domain type',\n",
    "    'has_attachment': 'Has file attachment (0/1)',\n",
    "    'weekend_sent': 'Sent on weekend (0/1)'\n",
    "}\n",
    "\n",
    "for feature, description in feature_descriptions.items():\n",
    "    print(f\"â€¢ {feature}: {description}\")\n",
    "\n",
    "# Quick analysis by email type\n",
    "print(\"\\nðŸ“Š Feature patterns by email type:\")\n",
    "for email_type in df['email_type'].unique():\n",
    "    subset = df[df['email_type'] == email_type]\n",
    "    print(f\"\\n{email_type} emails:\")\n",
    "    print(f\"  Avg exclamation marks: {subset['exclamation_marks'].mean():.1f}\")\n",
    "    print(f\"  Avg capital letters: {subset['capital_letters'].mean():.1f}\")\n",
    "    print(f\"  Avg links: {subset['links_count'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85121078",
   "metadata": {},
   "source": [
    "**Key Insight:** Spam emails have more exclamation marks, capital letters, and links!\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”§ STEP 3: Handle Categorical Variables\n",
    "\n",
    "### Q3: How do we convert text features to numbers?\n",
    "\n",
    "**Answer:** Use dummy variables (one-hot encoding) to convert categories into 0/1 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1c224aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before encoding:\n",
      "Columns: ['word_count', 'exclamation_marks', 'capital_letters', 'links_count', 'time_of_day', 'sender_domain', 'has_attachment', 'weekend_sent', 'email_type']\n",
      "Unique domains: ['gmail' 'hotmail' 'yahoo' 'company' 'work' 'promo' 'ads']\n",
      "\n",
      "After encoding:\n",
      "Columns: ['word_count', 'exclamation_marks', 'capital_letters', 'links_count', 'time_of_day', 'has_attachment', 'weekend_sent', 'email_type', 'domain_ads', 'domain_company', 'domain_gmail', 'domain_hotmail', 'domain_promo', 'domain_work', 'domain_yahoo']\n",
      "New domain columns: ['domain_ads', 'domain_company', 'domain_gmail', 'domain_hotmail', 'domain_promo', 'domain_work', 'domain_yahoo']\n",
      "\n",
      "Sample of encoded domain features:\n",
      "   domain_ads  domain_company  domain_gmail  domain_hotmail  domain_promo  \\\n",
      "0       False           False          True           False         False   \n",
      "1       False           False          True           False         False   \n",
      "2       False           False          True           False         False   \n",
      "3       False           False         False            True         False   \n",
      "4       False           False          True           False         False   \n",
      "\n",
      "   domain_work  domain_yahoo  \n",
      "0        False         False  \n",
      "1        False         False  \n",
      "2        False         False  \n",
      "3        False         False  \n",
      "4        False         False  \n"
     ]
    }
   ],
   "source": [
    "print(\"Before encoding:\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Unique domains: {df['sender_domain'].unique()}\")\n",
    "\n",
    "# Convert sender_domain to dummy variables\n",
    "df_encoded = pd.get_dummies(df, columns=['sender_domain'], prefix='domain')\n",
    "\n",
    "print(\"\\nAfter encoding:\")\n",
    "print(f\"Columns: {list(df_encoded.columns)}\")\n",
    "print(f\"New domain columns: {[col for col in df_encoded.columns if col.startswith('domain_')]}\")\n",
    "\n",
    "# Show the encoding result\n",
    "print(\"\\nSample of encoded domain features:\")\n",
    "domain_cols = [col for col in df_encoded.columns if col.startswith('domain_')]\n",
    "print(df_encoded[['sender_domain'] + domain_cols].head() if 'sender_domain' in df_encoded.columns else df_encoded[domain_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9dcfb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ—‘ï¸ STEP 4: Remove Useless Features\n",
    "\n",
    "### Q4: What features should we always remove?\n",
    "\n",
    "**Answer:** ID columns, random noise, and duplicate information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "98131f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Added some useless features:\n",
      "â€¢ email_id: Just an ID number\n",
      "â€¢ random_noise: Random meaningless numbers\n",
      "â€¢ duplicate_word_count: Same as word_count\n",
      "\n",
      "Before removal: 18 features\n",
      "All features: ['word_count', 'exclamation_marks', 'capital_letters', 'links_count', 'time_of_day', 'has_attachment', 'weekend_sent', 'email_type', 'domain_ads', 'domain_company', 'domain_gmail', 'domain_hotmail', 'domain_promo', 'domain_work', 'domain_yahoo', 'email_id', 'random_noise', 'duplicate_word_count']\n",
      "\n",
      "After removal: 15 features\n",
      "âœ… Remaining: ['word_count', 'exclamation_marks', 'capital_letters', 'links_count', 'time_of_day', 'has_attachment', 'weekend_sent', 'email_type', 'domain_ads', 'domain_company', 'domain_gmail', 'domain_hotmail', 'domain_promo', 'domain_work', 'domain_yahoo']\n"
     ]
    }
   ],
   "source": [
    "# Let's add some bad features for practice\n",
    "df_encoded['email_id'] = range(1, len(df_encoded) + 1)  # ID column\n",
    "df_encoded['random_noise'] = np.random.randint(1, 100, len(df_encoded))  # Random numbers\n",
    "df_encoded['duplicate_word_count'] = df_encoded['word_count']  # Duplicate feature\n",
    "\n",
    "print(\"âŒ Added some useless features:\")\n",
    "print(\"â€¢ email_id: Just an ID number\")\n",
    "print(\"â€¢ random_noise: Random meaningless numbers\") \n",
    "print(\"â€¢ duplicate_word_count: Same as word_count\")\n",
    "\n",
    "print(f\"\\nBefore removal: {len(df_encoded.columns)} features\")\n",
    "print(f\"All features: {list(df_encoded.columns)}\")\n",
    "\n",
    "# Remove the obvious bad features\n",
    "features_to_remove = ['email_id', 'random_noise', 'duplicate_word_count']\n",
    "df_clean = df_encoded.drop(columns=features_to_remove)\n",
    "\n",
    "print(f\"\\nAfter removal: {len(df_clean.columns)} features\")\n",
    "print(f\"âœ… Remaining: {list(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80382018",
   "metadata": {},
   "source": [
    "**Key Rule:** If a human can't explain why a feature would help, remove it!\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š STEP 5: Statistical Feature Selection\n",
    "\n",
    "### Q5: How do we find the most important features automatically?\n",
    "\n",
    "**Answer:** Use statistical tests to measure how well each feature predicts the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b60548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features to analyze: 14\n",
      "Target classes: ['Personal', 'Promotional', 'Spam']\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "feature_columns = [col for col in df_clean.columns if col != 'email_type']\n",
    "X = df_clean[feature_columns]\n",
    "y = df_clean['email_type']\n",
    "\n",
    "print(f\"Features to analyze: {len(X.columns)}\")\n",
    "print(f\"Target classes: {list(y.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0556146",
   "metadata": {},
   "source": [
    "### Method A: Filter Method (SelectKBest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a0070930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Method A: Statistical Filter (SelectKBest)\n",
      "Feature importance scores:\n",
      "  word_count: 92.23\n",
      "  exclamation_marks: 71.58\n",
      "  capital_letters: 110.25\n",
      "  links_count: 57.51\n",
      "  time_of_day: 4.52\n",
      "  has_attachment: 5.26\n",
      "  weekend_sent: 2.80\n",
      "  domain_ads: 9.00\n",
      "  domain_company: 9.00\n",
      "  domain_gmail: 13.50\n",
      "  domain_hotmail: 2.25\n",
      "  domain_promo: 9.00\n",
      "  domain_work: 9.00\n",
      "  domain_yahoo: 2.25\n",
      "\n",
      "âœ… Top 5 features selected: ['word_count', 'exclamation_marks', 'capital_letters', 'links_count', 'domain_gmail']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ” Method A: Statistical Filter (SelectKBest)\")\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Feature importance scores:\")\n",
    "feature_scores = selector.scores_\n",
    "for feature, score in zip(X.columns, feature_scores):\n",
    "    print(f\"  {feature}: {score:.2f}\")\n",
    "\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(f\"\\nâœ… Top 5 features selected: {list(selected_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24645322",
   "metadata": {},
   "source": [
    "### Method B: Wrapper Method (RFE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7d55218b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Method B: Wrapper Method (RFE)\n",
      "âœ… RFE selected features: ['word_count', 'exclamation_marks', 'capital_letters', 'time_of_day', 'has_attachment']\n",
      "\n",
      "Feature rankings (1 = best):\n",
      "  word_count: 1\n",
      "  exclamation_marks: 1\n",
      "  capital_letters: 1\n",
      "  links_count: 7\n",
      "  time_of_day: 1\n",
      "  has_attachment: 1\n",
      "  weekend_sent: 6\n",
      "  domain_ads: 10\n",
      "  domain_company: 3\n",
      "  domain_gmail: 2\n",
      "  domain_hotmail: 9\n",
      "  domain_promo: 5\n",
      "  domain_work: 4\n",
      "  domain_yahoo: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ”„ Method B: Wrapper Method (RFE)\")\n",
    "rfe_model = LogisticRegression(random_state=42, max_iter=10000)\n",
    "rfe_selector = RFE(rfe_model, n_features_to_select=5)\n",
    "rfe_selector.fit(X, y)\n",
    "\n",
    "rfe_selected = X.columns[rfe_selector.support_]\n",
    "print(f\"âœ… RFE selected features: {list(rfe_selected)}\")\n",
    "\n",
    "# Show feature rankings\n",
    "print(\"\\nFeature rankings (1 = best):\")\n",
    "for feature, rank in zip(X.columns, rfe_selector.ranking_):\n",
    "    print(f\"  {feature}: {rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2130a49",
   "metadata": {},
   "source": [
    "### Method C: Embedded Method (Random Forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3660d328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŒ³ Method C: Embedded Method (Random Forest)\n",
      "Random Forest feature importance:\n",
      "  word_count: 0.230\n",
      "  capital_letters: 0.214\n",
      "  exclamation_marks: 0.190\n",
      "  links_count: 0.140\n",
      "  time_of_day: 0.056\n",
      "  domain_gmail: 0.032\n",
      "  domain_company: 0.028\n",
      "  domain_work: 0.027\n",
      "  domain_promo: 0.024\n",
      "  has_attachment: 0.020\n",
      "  domain_ads: 0.019\n",
      "  weekend_sent: 0.010\n",
      "  domain_yahoo: 0.006\n",
      "  domain_hotmail: 0.004\n",
      "\n",
      "âœ… Important features (>0.05): ['word_count', 'capital_letters', 'exclamation_marks', 'links_count', 'time_of_day']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸŒ³ Method C: Embedded Method (Random Forest)\")\n",
    "rf = RandomForestClassifier(n_estimators=3000, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "print(\"Random Forest feature importance:\")\n",
    "importance_scores = rf.feature_importances_\n",
    "feature_importance = list(zip(X.columns, importance_scores))\n",
    "feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for feature, importance in feature_importance:\n",
    "    print(f\"  {feature}: {importance:.3f}\")\n",
    "\n",
    "# Select features above threshold\n",
    "threshold = 0.05\n",
    "important_features = [feature for feature, importance in feature_importance if importance > threshold]\n",
    "print(f\"\\nâœ… Important features (>{threshold}): {important_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b4178",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸš€ STEP 6: Build Complete Pipeline\n",
    "\n",
    "### Q6: How do we combine all preprocessing steps?\n",
    "\n",
    "**Answer:** Use a Pipeline to chain scaling, selection, and classification together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cdc04293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 21\n",
      "Test set size: 9\n",
      "\n",
      "âœ… Pipeline accuracy: 1.000\n",
      "ðŸ“‹ Pipeline selected features: ['word_count', 'exclamation_marks', 'capital_letters', 'links_count', 'domain_gmail']\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('variance_filter', VarianceThreshold(threshold=0)),  # Remove zero variance\n",
    "    ('scaler', StandardScaler()),                         # Scale features\n",
    "    ('selector', SelectKBest(score_func=f_classif, k=5)), # Select top 5\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the pipeline\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(f\"\\nâœ… Pipeline accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Show which features were selected by the pipeline\n",
    "# First get features that survived variance filtering\n",
    "variance_mask = pipeline.named_steps['variance_filter'].get_support()\n",
    "features_after_variance = X.columns[variance_mask]\n",
    "\n",
    "# Then apply selector mask to the remaining features\n",
    "selector_mask = pipeline.named_steps['selector'].get_support()\n",
    "final_selected = features_after_variance[selector_mask]\n",
    "\n",
    "print(f\"ðŸ“‹ Pipeline selected features: {list(final_selected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d1feeb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ STEP 7: Make Predictions\n",
    "\n",
    "### Q7: How well does our model perform?\n",
    "\n",
    "**Answer:** Test it on new data and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1cc5b5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions:\n",
      "Email 1: Actual=Spam         | Predicted=Spam         | Confidence=0.99\n",
      "Email 2: Actual=Promotional  | Predicted=Promotional  | Confidence=0.72\n",
      "Email 3: Actual=Spam         | Predicted=Spam         | Confidence=0.97\n",
      "Email 4: Actual=Promotional  | Predicted=Promotional  | Confidence=0.71\n",
      "Email 5: Actual=Personal     | Predicted=Personal     | Confidence=0.62\n",
      "Email 6: Actual=Personal     | Predicted=Personal     | Confidence=0.96\n",
      "Email 7: Actual=Spam         | Predicted=Spam         | Confidence=0.96\n",
      "Email 8: Actual=Spam         | Predicted=Spam         | Confidence=0.72\n",
      "Email 9: Actual=Promotional  | Predicted=Promotional  | Confidence=0.72\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = pipeline.predict(X_test)\n",
    "probabilities = pipeline.predict_proba(X_test)\n",
    "\n",
    "print(\"Sample predictions:\")\n",
    "class_names = pipeline.classes_\n",
    "for i in range(len(X_test)):\n",
    "    actual = y_test.iloc[i]\n",
    "    predicted = predictions[i]\n",
    "    confidence = max(probabilities[i])\n",
    "    print(f\"Email {i+1}: Actual={actual:12} | Predicted={predicted:12} | Confidence={confidence:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
